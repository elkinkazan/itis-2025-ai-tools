{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexander-toschev/ai-tools/blob/main/tasks/Task6_FakeAnalysisPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# DO NOT MODIFY  !!!\n",
        "# DO NOT EXECUTE !!!\n",
        "!pip install --upgrade gspread pandas google-auth\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from IPython.display import display\n",
        "import random\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "U9ynQEDVRQgF"
      },
      "id": "U9ynQEDVRQgF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILL THIS\n",
        "student_name = \"ELON MUSK\"\n",
        "group_id = \"11-101\""
      ],
      "metadata": {
        "id": "gjq46DWTRRll"
      },
      "id": "gjq46DWTRRll",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY  !!!\n",
        "# DO NOT EXECUTE !!!\n",
        "SPREADSHEET_URL = \"https://docs.google.com/spreadsheets/d/1Kfxj2eDFl7xQnXw7Fpb9bwghc65o8xf--VpNxrdWHaY/edit?gid=0#gid=0\"\n",
        "sh = gc.open_by_url(SPREADSHEET_URL)\n",
        "worksheet = sh.sheet1\n",
        "\n",
        "# Ensure header row exists\n",
        "if not worksheet.get_all_values():\n",
        "    worksheet.append_row([\"Student Name\", \"Group\",\"TaskID\", \"Score\"])\n",
        "\n",
        "\n",
        "# MAIN NOTEBOOK GOES HERE\n",
        "task_id = \"Task6_FakeAnalysisPipeline\"\n",
        "score = 0\n",
        "max_score = 25"
      ],
      "metadata": {
        "id": "9AT_A3Y_RT4e"
      },
      "id": "9AT_A3Y_RT4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéì –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–∏–¥–µ–æ- –∏ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞"
      ],
      "metadata": {
        "id": "bxfH9sqsPkm-"
      },
      "id": "bxfH9sqsPkm-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "!pip install ffmpeg-python resemblyzer scikit-learn tensorflow matplotlib tqdm librosa opencv-python-headless"
      ],
      "metadata": {
        "id": "wuvVOD77PoBa"
      },
      "id": "wuvVOD77PoBa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. –ò–º–ø–æ—Ä—Ç—ã\n",
        "import ffmpeg\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2"
      ],
      "metadata": {
        "id": "eg_OKAhRPqOj"
      },
      "id": "eg_OKAhRPqOj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ LA\n",
        "model = load_model(\"la_model.keras\")  # –æ–±—É—á–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ\n",
        "encoder = VoiceEncoder()\n",
        "\n",
        "# –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞–º\n",
        "VIDEO_DIR = \"/content/videos\"\n",
        "VIDEO_LIST = [os.path.join(VIDEO_DIR, f\"video{i}.mp4\") for i in range(1, 7)]"
      ],
      "metadata": {
        "id": "9f0J4MmlPuUR"
      },
      "id": "9f0J4MmlPuUR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ\n",
        "def extract_audio_from_video(video_path, output_wav):\n",
        "    (\n",
        "        ffmpeg\n",
        "        .input(video_path)\n",
        "        .output(output_wav, ac=1, ar=16000)\n",
        "        .overwrite_output()\n",
        "        .run(quiet=True)\n",
        "    )\n"
      ],
      "metadata": {
        "id": "INFRM7u4P5GH"
      },
      "id": "INFRM7u4P5GH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏\n",
        "def predict_audio_model(file_path):\n",
        "    wav = preprocess_wav(Path(file_path))\n",
        "    # YOU CODE HERE USING THE LA model and resembler predict the video\n",
        "    embed =\n",
        "    prediction =\n",
        "    return prediction, prediction >= 0.5"
      ],
      "metadata": {
        "id": "6QO8-vuMP7Ku"
      },
      "id": "6QO8-vuMP7Ku",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑\n",
        "def extract_simple_features(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    # YOu code starts here\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "    mfcc_std =\n",
        "    zcr =\n",
        "    centroid =\n",
        "    # YOUR CODE ENDS HERE\n",
        "    return {\n",
        "        \"mfcc_std_mean\": np.mean(mfcc_std),\n",
        "        \"zcr_mean\": np.mean(zcr),\n",
        "        \"centroid_mean\": np.mean(centroid)\n",
        "    }"
      ],
      "metadata": {
        "id": "1LzK9DFtQJ6Z"
      },
      "id": "1LzK9DFtQJ6Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_fake_audio_detector(file_path):\n",
        "    f = extract_simple_features(file_path)\n",
        "    is_fake = f[\"mfcc_std_mean\"] < 25 or f[\"zcr_mean\"] > 0.1 or f[\"centroid_mean\"] > 3500\n",
        "    return f, is_fake"
      ],
      "metadata": {
        "id": "88sNUyRGQTzt"
      },
      "id": "88sNUyRGQTzt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞ —Å –ø–æ–º–æ—â—å—é FFException-–ø–æ–¥—Ö–æ–¥–∞\n",
        "IMG_SIZE = 299\n",
        "MODEL_PATH = 'xception_dfdc_trained.keras'  # –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\n",
        "\n",
        "# === –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ===\n",
        "model_exception = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "\n",
        "# === –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Ö–æ–¥–∞ ===\n",
        "def preprocess_face(face):\n",
        "    face = cv2.resize(face, (IMG_SIZE, IMG_SIZE))\n",
        "    face = face.astype('float32') / 255.0\n",
        "    return np.expand_dims(face, axis=0)\n",
        "\n",
        "# === –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ª–∏—Ü–∞ ===\n",
        "def extract_face(frame):\n",
        "    face_locations = face_recognition.face_locations(frame)\n",
        "    if not face_locations:\n",
        "        return None\n",
        "    top, right, bottom, left = face_locations[0]\n",
        "    face = frame[top:bottom, left:right]\n",
        "    return face\n",
        "\n",
        "def analyze_video_stream(video_path, max_frames=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    predictions = []\n",
        "    frame_count = 0\n",
        "\n",
        "    while frame_count < max_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        face = extract_face(frame)\n",
        "        if face is None:\n",
        "            continue\n",
        "        # your code starts here\n",
        "        input_face =\n",
        "        pred =\n",
        "        predictions.append(pred)\n",
        "        frame_count += 1\n",
        "    cap.release()\n",
        "    if predictions:\n",
        "        return \"Fake detected\",np.mean(predictions) > 0.5\n",
        "    else:\n",
        "        return None, False"
      ],
      "metadata": {
        "id": "XIkxSQMQQWy3"
      },
      "id": "XIkxSQMQQWy3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680ceff5",
      "metadata": {
        "id": "680ceff5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞\n",
        "\n",
        "def analyze_video_file(video_path):\n",
        "    print(f\"\\nüìÇ –§–∞–π–ª: {os.path.basename(video_path)}\")\n",
        "    audio_path = video_path.replace(\".mp4\", \".wav\")\n",
        "    extract_audio_from_video(video_path, audio_path)\n",
        "    visual_log, visual_flag = analyze_video_stream(video_path)\n",
        "    model_score, model_label = predict_audio_model(audio_path)\n",
        "    heuristics, heur_label = simple_fake_audio_detector(audio_path)\n",
        "\n",
        "    print(\"üé• –í–∏–¥–µ–æ (–ø–æ –∫–∞–¥—Ä–∞–º):\", visual_log, \"‚õî\" if visual_flag else \"‚úÖ\")\n",
        "    print(\"üîä –ê—É–¥–∏–æ (Resemblyzer+NN):\", \"Fake\" if model_label else \"Real\", f\"(score={model_score:.3f})\")\n",
        "    print(\"üîé –ê—É–¥–∏–æ (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞):\", \"Fake\" if heur_label else \"Real\", heuristics)\n",
        "\n",
        "    return {\n",
        "        \"video\": os.path.basename(video_path),\n",
        "        \"visual_flag\": int(visual_flag),\n",
        "        \"nn_result\": int(model_label),\n",
        "        \"heur_result\": int(heur_label),\n",
        "        \"model_score\": model_score,\n",
        "        \"heuristics\": heuristics\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ –≤—Å–µ—Ö –≤–∏–¥–µ–æ\n",
        "results = []\n",
        "for video_path in VIDEO_LIST:\n",
        "    result = analyze_video_file(video_path)\n",
        "    results.append(result)\n",
        "\n",
        "# –¢–µ—Å—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "\n",
        "def test_pipeline_structure(results):\n",
        "    assert len(results) == 6, \"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å 6 –≤–∏–¥–µ–æ\"\n",
        "    for r in results:\n",
        "        assert 'nn_result' in r and 'heur_result' in r and 'visual_flag' in r\n",
        "        score += 5\n",
        "        assert isinstance(r['model_score'], float)\n",
        "        score += 10\n",
        "        assert isinstance(r['heuristics'], dict)\n",
        "        score += 10\n",
        "    print(\"‚úÖ Pipeline test passed.\")\n",
        "\n",
        "test_pipeline_structure(results)"
      ],
      "metadata": {
        "id": "QR0KW4gcRE4E"
      },
      "id": "QR0KW4gcRE4E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY  !!!\n",
        "# DO NOT EXECUTE !!!\n",
        "# Save the result to Google Sheets\n",
        "from datetime import datetime\n",
        "\n",
        "# Get current date and time\n",
        "now = datetime.now()\n",
        "timestamp = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "worksheet.append_row([student_name,group_id, task_id, score, timestamp])\n",
        "\n",
        "print(f\"Test completed! {student_name}, your score is {score}/{max_score}.\")"
      ],
      "metadata": {
        "id": "V3AqOadSRjuT"
      },
      "id": "V3AqOadSRjuT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}