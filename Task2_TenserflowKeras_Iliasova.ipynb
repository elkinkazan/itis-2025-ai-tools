{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elkinkazan/itis-2025-ai-tools/blob/main/Task2_TenserflowKeras_Iliasova.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY  !!!\n",
        "# DO NOT EXECUTE !!!\n",
        "!pip install --upgrade gspread pandas google-auth\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from IPython.display import display\n",
        "import random\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqhoIz8hAKQ2",
        "outputId": "3fb04ca9-808d-4eb9-8a01-2da1f0bf01fc"
      },
      "id": "SqhoIz8hAKQ2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.1.31)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FILL THIS\n",
        "student_name = \"ELVIRA ILIASOVA\"\n",
        "group_id = \"11-451\""
      ],
      "metadata": {
        "id": "cppTCB4iALgr"
      },
      "id": "cppTCB4iALgr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY  !!!\n",
        "# DO NOT EXECUTE !!!\n",
        "SPREADSHEET_URL = \"https://docs.google.com/spreadsheets/d/1Kfxj2eDFl7xQnXw7Fpb9bwghc65o8xf--VpNxrdWHaY/edit?gid=0#gid=0\"\n",
        "sh = gc.open_by_url(SPREADSHEET_URL)\n",
        "worksheet = sh.sheet1\n",
        "\n",
        "# Ensure header row exists\n",
        "if not worksheet.get_all_values():\n",
        "    worksheet.append_row([\"Student Name\", \"Group\",\"TaskID\", \"Score\"])\n"
      ],
      "metadata": {
        "id": "k_6adWQPAPpg"
      },
      "id": "k_6adWQPAPpg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN NOTEBOOK GOES HERE\n",
        "task_id = \"Task2_KerasTenserflow\"\n",
        "global score\n",
        "score = 0\n",
        "max_score = 10"
      ],
      "metadata": {
        "id": "dgK29Z8s8kmb"
      },
      "id": "dgK29Z8s8kmb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a4a86b0c",
      "metadata": {
        "id": "a4a86b0c"
      },
      "source": [
        "# ü§ñ –ü—Ä–∞–∫—Ç–∏–∫–∞ –ø–æ Keras –∏ TensorFlow\n",
        "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –≤—ã —Ä–µ–∞–ª–∏–∑—É–µ—Ç–µ –∏ –æ–±—É—á–∏—Ç–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ `Keras`, –∏—Å–ø–æ–ª—å–∑—É—è `TensorFlow` –∫–∞–∫ backend.\n",
        "–í—ã –±—É–¥–µ—Ç–µ:\n",
        "- –ó–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (MNIST)\n",
        "- –°—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å —Å `Sequential`\n",
        "- –î–æ–ø–∏—Å—ã–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "- –ü—Ä–æ—Ö–æ–¥–∏—Ç—å –∞–≤—Ç–æ—Ç–µ—Å—Ç—ã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee65ee0",
      "metadata": {
        "id": "3ee65ee0"
      },
      "outputs": [],
      "source": [
        "# üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2fc8e3",
      "metadata": {
        "id": "4c2fc8e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe5bda5-dcd6-4e17-ce3f-ee071f874914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b72b9a1f",
      "metadata": {
        "id": "b72b9a1f"
      },
      "source": [
        "## üß† –ó–∞–¥–∞–Ω–∏–µ: —Å–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ Keras\n",
        "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:** –¥–æ–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `create_model`, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥–µ–ª—å `Sequential` —Å:\n",
        "- Flatten –≤—Ö–æ–¥–æ–º\n",
        "- Dense(128, relu)\n",
        "- Dense(10, softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a548afae",
      "metadata": {
        "id": "a548afae"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    # YOUR CODE START\n",
        "    model = Sequential([\n",
        "        Input(shape=(28, 28)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "    # YOUR CODE END"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a40f593",
      "metadata": {
        "id": "0a40f593"
      },
      "source": [
        "## üéØ –ó–∞–¥–∞–Ω–∏–µ: —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
        "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:** –¥–æ–ø–∏—à–∏—Ç–µ `check_prediction`, –∫–æ—Ç–æ—Ä–∞—è:\n",
        "- –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "- –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏\n",
        "- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a41c9d",
      "metadata": {
        "id": "c2a41c9d"
      },
      "outputs": [],
      "source": [
        "def check_prediction(model):\n",
        "    # YOUR CODE START\n",
        "    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1000 –ø—Ä–∏–º–µ—Ä–æ–≤)\n",
        "    model.fit(X_train[:1000], y_train_cat[:1000], epochs=3, verbose=0)\n",
        "\n",
        "    import numpy as np\n",
        "    sample = X_test[0:1]  # –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
        "    pred = model.predict(sample, verbose=0)  # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
        "    predicted = int(np.argmax(pred))  # –∏–Ω–¥–µ–∫—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é\n",
        "    actual = int(y_test[0])  # –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –º–µ—Ç–∫–∞\n",
        "    return predicted, actual\n",
        "    # YOUR CODE END\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "046a0d0b",
      "metadata": {
        "id": "046a0d0b"
      },
      "source": [
        "## üöÄ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ: —Å–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å (CNN)\n",
        "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:** –¥–æ–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `create_cnn_model`, –∫–æ—Ç–æ—Ä–∞—è –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å:\n",
        "- –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π `Conv2D`\n",
        "- MaxPooling\n",
        "- Dropout\n",
        "- Flatten\n",
        "- Dense\n",
        "- Dropout\n",
        "- Dense-–≤—ã—Ö–æ–¥\n",
        "\n",
        "–≠—Ç–∞ –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ñ–æ—Ä–º–∞—Ç–æ–º –≤—Ö–æ–¥–∞ `(28, 28, 1)` ‚Äî —á/–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e6d3177",
      "metadata": {
        "id": "5e6d3177"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = Sequential([\n",
        "        # –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π —Å 32 —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ 3x3 –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π relu\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "\n",
        "        # MaxPooling —Å–ª–æ–π –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –ø–ª–æ—Ç–Ω—ã–º —Å–ª–æ–µ–º\n",
        "        Flatten(),\n",
        "\n",
        "        # –ü–ª–æ—Ç–Ω—ã–π —Å–ª–æ–π\n",
        "        Dense(128, activation='relu'),\n",
        "\n",
        "        # –ï—â–µ –æ–¥–∏–Ω Dropout\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3861d71a",
      "metadata": {
        "id": "3861d71a"
      },
      "source": [
        "## üß™ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "–°–æ–∑–¥–∞–¥–∏–º –≤—Ö–æ–¥ –∏ –æ–±—É—á–∏–º CNN –Ω–∞ –º–∞–ª–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ec2c10c",
      "metadata": {
        "id": "5ec2c10c"
      },
      "outputs": [],
      "source": [
        "def test_cnn_model():\n",
        "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è CNN: –¥–æ–±–∞–≤–∏–º –∫–∞–Ω–∞–ª\n",
        "    X_train_cnn = X_train.reshape(-1, 28, 28, 1)\n",
        "    X_test_cnn = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "    model_cnn = create_cnn_model()\n",
        "    model_cnn.fit(X_train_cnn[:2000], y_train_cat[:2000], epochs=5, verbose=1, validation_split=0.1)\n",
        "    loss, acc = model_cnn.evaluate(X_test_cnn[:1000], y_test_cat[:1000], verbose=0)\n",
        "    print(\"‚úÖ Accuracy –Ω–∞ —Ç–µ—Å—Ç–µ:\", round(acc, 3))\n",
        "    return round(acc, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0aae6e7",
      "metadata": {
        "id": "e0aae6e7"
      },
      "source": [
        "## ‚úÖ –ê–≤—Ç–æ—Ç–µ—Å—Ç—ã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3073079f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3073079f",
        "outputId": "66dff316-08c5-4b0c-de0c-9a4b9a77c9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.4450 - loss: 1.6444 - val_accuracy: 0.8750 - val_loss: 0.4305\n",
            "Epoch 2/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8242 - loss: 0.5805 - val_accuracy: 0.9200 - val_loss: 0.2789\n",
            "Epoch 3/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8725 - loss: 0.4322 - val_accuracy: 0.9350 - val_loss: 0.2446\n",
            "Epoch 4/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8992 - loss: 0.3487 - val_accuracy: 0.9300 - val_loss: 0.2104\n",
            "Epoch 5/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9125 - loss: 0.2834 - val_accuracy: 0.9400 - val_loss: 0.1832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Accuracy –Ω–∞ —Ç–µ—Å—Ç–µ: 0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 11.487s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Score: 10/10\n"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "\n",
        "class TestKerasModel(unittest.TestCase):\n",
        "    def test_prediction(self):\n",
        "        model = create_model()\n",
        "        predicted, actual = check_prediction(model)\n",
        "        self.assertIsInstance(predicted, int)\n",
        "        self.assertIsInstance(actual, int)\n",
        "        self.assertEqual(predicted, actual)\n",
        "        global score\n",
        "        score += 5\n",
        "    def test_cnn(self):\n",
        "        accuracy = test_cnn_model()\n",
        "        self.assertGreaterEqual(accuracy, 0.89)\n",
        "        global score\n",
        "        score += 5\n",
        "\n",
        "# Run tests\n",
        "score = 0\n",
        "max_score = 10\n",
        "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
        "print(f\"Student Score: {score}/{max_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# DO NOT MODIFY  !!!\n",
        "# DO NOT EXECUTE !!!\n",
        "# Save the result to Google Sheets\n",
        "from datetime import datetime\n",
        "\n",
        "# Get current date and time\n",
        "now = datetime.now()\n",
        "timestamp = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "worksheet.append_row([student_name,group_id, task_id, score, timestamp])\n",
        "\n",
        "print(f\"Test completed! {student_name}, your score is {score}/{max_score}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSMCICueAW1y",
        "outputId": "55c524f5-f85e-4573-bb21-63e018db75fa"
      },
      "id": "TSMCICueAW1y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test completed! ELON MUSK, your score is 10/10.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}